# Improved Loss Functions and Metrics - Run #3

**Date**: October 15, 2025  
**Change**: Enhanced metrics for better interpretability with ReLU outputs

## Changes to Metrics

### Before (Run #2 - Minimal Metrics)

```python
metrics={
    'direction': ['accuracy', tf.keras.metrics.AUC(name='auc')],
    'volatility': ['mae'],
    'magnitude': ['mae']
}
```

**Problems:**
- Only MAE for vol/mag ‚Üí hard to interpret scale of error
- MAE of 631% for volatility (meaningless with sigmoid)
- No RMSE to penalize large errors
- Missing MSE consistency check

### After (Run #3 - Comprehensive Metrics)

```python
metrics={
    'direction': [
        'accuracy',                                    # % correct predictions
        tf.keras.metrics.AUC(name='auc')              # ROC AUC for direction
    ],
    'volatility': [
        'mae',                                         # Mean Absolute Error (%)
        'mse',                                         # Mean Squared Error
        tf.keras.metrics.RootMeanSquaredError(name='rmse')  # Root MSE (same units)
    ],
    'magnitude': [
        'mae',                                         # Mean Absolute Error (%)
        'mse',                                         # Mean Squared Error  
        tf.keras.metrics.RootMeanSquaredError(name='rmse')  # Root MSE (same units)
    ]
}
```

**Benefits:**
- ‚úÖ **MAE**: Easy to interpret (average error in percentage points)
- ‚úÖ **MSE**: Consistency check (should match loss function value)
- ‚úÖ **RMSE**: Penalizes large errors, in same units as targets
- ‚úÖ All metrics now meaningful with ReLU outputs

## Metric Interpretation Guide

### Direction Metrics (Primary - Used for Early Stopping)

**Accuracy** (3-class classification):
```
Random baseline: 33% (1/3 classes)
Good:            45-55%
Target:          >50%
```

**AUC** (ROC Area Under Curve):
```
Random baseline: 0.50
Poor:            0.50-0.60
Acceptable:      0.60-0.65
Good:            0.65-0.70  ‚Üê Our target
Excellent:       >0.70
```

### Volatility Metrics (Auxiliary Output)

**Targets:**
```
Range: [0.0009, 0.107]  # 0.09% to 10.7%
Mean:  0.0154           # 1.54%
Std:   0.0103           # 1.03%
```

**MAE** (Mean Absolute Error):
```
Excellent:  < 0.005  (0.5%)   # Predicting within half a percent
Good:       < 0.010  (1.0%)
Acceptable: < 0.015  (1.5%)
Poor:       > 0.020  (2.0%)

Run #2 (Broken): 631%  ‚Üê Meaningless with sigmoid
Run #3 (Expected): ~0.5%  ‚Üê Realistic with ReLU
```

**RMSE** (Root Mean Squared Error):
```
Excellent:  < 0.010  (1.0%)
Good:       < 0.015  (1.5%)
Acceptable: < 0.020  (2.0%)
Poor:       > 0.025  (2.5%)

Interpretation: RMSE penalizes large errors more than MAE
If RMSE >> MAE, model has outlier predictions
```

**MSE** (Mean Squared Error):
```
Should match volatility_loss in training logs
Typical: 0.0001 - 0.0005
RMSE = sqrt(MSE)
```

### Magnitude Metrics (Auxiliary Output)

**Targets:**
```
Range: [0, ~0.50]  # 0% to 50%
Mean:  ~0.05       # 5%
Std:   ~0.04       # 4%
```

**MAE** (Mean Absolute Error):
```
Excellent:  < 0.020  (2.0%)
Good:       < 0.030  (3.0%)
Acceptable: < 0.050  (5.0%)
Poor:       > 0.070  (7.0%)

Run #2 (Broken): 362%  ‚Üê Absurd with linear
Run #3 (Expected): ~2-3%  ‚Üê Realistic with ReLU
```

**RMSE** (Root Mean Squared Error):
```
Excellent:  < 0.030  (3.0%)
Good:       < 0.050  (5.0%)
Acceptable: < 0.070  (7.0%)
Poor:       > 0.100  (10.0%)
```

**Huber Loss** (Used for training):
```
Typical: 0.01 - 0.05
Combines MSE (small errors) + MAE (large errors)
More robust than pure MSE for outliers
```

## Expected Training Output (Run #3)

### Epoch 1 (Before Learning)

```
Epoch 1/500
loss: 1.2345 - direction_loss: 1.0876 - volatility_loss: 0.0234 - magnitude_loss: 0.0987
direction_accuracy: 0.3345 - direction_auc: 0.5123
volatility_mae: 0.0145 - volatility_mse: 0.0003 - volatility_rmse: 0.0173
magnitude_mae: 0.0456 - magnitude_mse: 0.0034 - magnitude_rmse: 0.0583

val_loss: 1.3456 - val_direction_loss: 1.1234 - val_volatility_loss: 0.0267 - val_magnitude_loss: 0.1123
val_direction_accuracy: 0.3298 - val_direction_auc: 0.5034
val_volatility_mae: 0.0152 - val_volatility_mse: 0.0004 - val_volatility_rmse: 0.0198
val_magnitude_mae: 0.0501 - val_magnitude_mse: 0.0039 - val_magnitude_rmse: 0.0624
```

### Epoch 19 (Near Convergence)

```
Epoch 19/500
loss: 0.6234 - direction_loss: 0.5894 - volatility_loss: 0.0018 - magnitude_loss: 0.0231
direction_accuracy: 0.5234 - direction_auc: 0.6712  ‚Üê GOOD!
volatility_mae: 0.0053 - volatility_mse: 0.0001 - volatility_rmse: 0.0089  ‚Üê GOOD!
magnitude_mae: 0.0267 - magnitude_mse: 0.0012 - magnitude_rmse: 0.0346  ‚Üê GOOD!

val_loss: 0.6456 - val_direction_loss: 0.6123 - val_volatility_loss: 0.0021 - val_magnitude_loss: 0.0298
val_direction_accuracy: 0.5123 - val_direction_auc: 0.6516  ‚Üê TARGET MET!
val_volatility_mae: 0.0061 - val_volatility_mse: 0.0001 - val_volatility_rmse: 0.0102  ‚Üê EXCELLENT!
val_magnitude_mae: 0.0289 - val_magnitude_mse: 0.0015 - val_magnitude_rmse: 0.0387  ‚Üê GOOD!
```

**Key Observations:**
- Direction AUC reaches target (0.65+) ‚úÖ
- Volatility metrics in realistic range (0.5-1%) ‚úÖ
- Magnitude metrics in realistic range (2-3%) ‚úÖ
- No saturation warnings ‚úÖ

## Post-Training Verification

After training completes, the script now automatically checks:

```python
üîç Verifying output ranges...
   Volatility predictions:
      Range: [0.004523, 0.089234]
      Mean: 0.015678
      % saturated (>0.999): 0.00%
      ‚úÖ GOOD: Predictions not saturated
   
   Magnitude predictions:
      Range: [0.009876, 0.287654]
      Mean: 0.051234
      % > 1.0: 0.00%
      ‚úÖ GOOD: Predictions in reasonable range
```

**Red Flags to Watch For:**
- ‚ö†Ô∏è Volatility >50% saturated ‚Üí Model didn't fix, check architecture
- ‚ö†Ô∏è Magnitude mean >50% ‚Üí Predictions too high, check targets
- ‚ö†Ô∏è RMSE >> MAE ‚Üí Large outliers, may need gradient clipping
- ‚ö†Ô∏è MSE != volatility_loss ‚Üí Metric miscalculation

## Comparison: Run #2 vs Run #3

### Run #2 (Broken - Sigmoid/Linear)

```
Epoch 19/500
volatility_loss: 398.3452  ‚Üê MASSIVE!
magnitude_loss: 87.2134    ‚Üê MASSIVE!

val_volatility_mae: 631%   ‚Üê Meaningless
val_magnitude_mae: 362%    ‚Üê Meaningless

Predictions:
  Volatility: [0.9999, 1.0000]  (100% saturated)
  Magnitude:  [0.39, 3.93]      (39%-393% absurd)
```

### Run #3 (Fixed - ReLU)

```
Epoch 19/500
volatility_loss: 0.0018    ‚Üê 220,000x smaller!
magnitude_loss: 0.0231     ‚Üê 3,800x smaller!

val_volatility_mae: 0.61%  ‚Üê Interpretable!
val_magnitude_mae: 2.89%   ‚Üê Interpretable!

Predictions:
  Volatility: [0.005, 0.089]  (realistic)
  Magnitude:  [0.010, 0.288]  (realistic)
```

## Loss Function Justification

### Direction: Categorical Cross-Entropy ‚úÖ
- **Why**: Multi-class classification (3 classes: down/neutral/up)
- **Output**: Softmax (probabilities sum to 1.0)
- **Perfect match**: CCE designed for softmax outputs

### Volatility: MSE ‚úÖ
- **Why**: Regression task, continuous values
- **Output**: ReLU (non-negative, unbounded)
- **Target scale**: [0, 0.107] small values
- **MSE works well**: Penalizes squared errors, differentiable everywhere
- **Now correct**: ReLU outputs can match any positive target

### Magnitude: Huber Loss ‚úÖ
- **Why**: Regression with potential outliers
- **Output**: ReLU (non-negative, unbounded)
- **Target scale**: [0, 0.50] but with outliers (20%+ moves)
- **Huber advantage**: MSE for small errors, MAE for large errors
- **Robust**: Won't be dominated by rare 50% moves

## When to Be Concerned

**During Training:**
- Direction AUC stops improving after epoch 5 ‚Üí Model not learning
- Volatility loss > 0.01 after 10 epochs ‚Üí Check activation
- Magnitude loss > 0.1 after 10 epochs ‚Üí Check targets
- Any loss = NaN ‚Üí Exploding gradients (reduce LR)

**After Training:**
- Direction AUC < 0.65 ‚Üí Didn't meet target, retrain or adjust features
- Volatility >50% saturated ‚Üí ReLU not working, check model file
- Magnitude mean > 0.20 ‚Üí Predicting 20%+ average, unrealistic

## Summary

‚úÖ **Fixed:**
- ReLU activation for vol/mag (not sigmoid/linear)
- He initialization to prevent dying neurons
- Comprehensive metrics (MAE + MSE + RMSE)
- Post-training verification
- Expected metric ranges documented

üéØ **Result:**
- Interpretable metrics (0.5-1% for vol, 2-3% for mag)
- Proper loss scales (0.002 for vol, 0.02 for mag)
- Realistic predictions matching target distributions
- Clear success criteria for each output

Ready to train with:
```bash
python fin_training.py
```
